{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear 1: solução analítica\n",
    "\n",
    "\n",
    "Dado o dataset $(\\mathbf{x}_{1}, y_{1}), \\dots ,(\\mathbf{x}_{N}, y_{N})$ onde $\\mathbf{x}_i \\in \\mathbb{R}^{n}$ e $y_i \\in \\mathbb{R}$, podemos aproximar a função escondida $f:\\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ (lembrando que $y_i =f(\\mathbf{x}_i)$) por meio de um modelo linear $h$:\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}, b) = \\mathbf{w}^\\top . \\mathbf{x}_{i} + b\n",
    "$$\n",
    "\n",
    "A saída de $h$ é uma transformação linear de $\\mathbf{x}_{i}$. Usamos a notação $h(\\mathbf{x}_{i}; \\mathbf{w}, b)$ para deixar claro que $h$ é um modelo parametrizado, i.e., a transformação $h$ é definida pelos parâmetros $\\mathbf{w}$ e $b$. Podemos pensar no vetor $\\mathbf{w}$ como um vetor de *pesos* controlando o efeito de cada *feauture* na predição.\n",
    "\n",
    "Adicionando uma feature a mais na obsevação $\\mathbf{x}_{i}$ (com o valor 1) podemos simplificar a notação do modelo:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}) = \\hat{y}_{i} = \\mathbf{w}^\\top . \\mathbf{x}_{i}\n",
    "$$\n",
    "\n",
    "Procuramos os melhores parametros $\\mathbf{w}$ de modo que a predição $\\hat{y}_{i}$ seja a mais próxima de $y_{i}$ de acordo com alguma métrica de erro. Usando o *erro quadrárico médio* como tal métrica podemos obter a seguinte função de custo:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}) = \\frac{1}{2}\\sum_{i=1}^{N}(\\hat{y}_{i} - y_{i})^{2}\n",
    "$$\n",
    "\n",
    "Desse modo, a tarefa de achar os parametros $\\mathbf{w}$ se torna a tarefa de encontrar os valores de $\\mathbf{w}$ para minimizar $J(\\mathbf{w})$.\n",
    "\n",
    "**Aqui vamos começar a explorar esse modelo olhando para um dataset bem simples**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import numpy as np\n",
    "from util import get_hausing_prices_data, plot_points_regression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O dataset\n",
    "\n",
    "Os dados que vamos trabalhar vão ser dados artificiais. Vamos pegar 100 observações com apenas uma *feature* (metros quadrados de um imóvel) e com isso vamos associar um valor (o preço desse imóvel em $). Nossa tarefa vai ser em contruir um modelo que consiga predizer o valor de imóveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_hausing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando os dados\n",
    "\n",
    "Acima temos algumas informações sobre os dados, podemos também visualizar cada ponto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Real estate prices prediction'\n",
    "xlabel = \"m\\u00b2\"\n",
    "ylabel = '$'\n",
    "plot_points_regression(X, y, title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modo de resolver o problema da regressão é por meio da forma fechada, a chamada **equação normal**:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = (X^T . X)^{-1} . X^T . y\n",
    "$$\n",
    "\n",
    "- Problema: os dados precisam caber na memória\n",
    "- Problema: conforme cresce o número de variáveis, o tempo da inversão da matriz fica proibitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "Implemente a predição usando o método de equações normais. Usando apenas a biblioteca **numpy** voce deve completar a função abaixo de modo a adicionar uma *feature* (com apenas 1s) ao dataset e realizar a computação descrita acima. Depois tire o comentário das linhas para ver o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the prediction using the normal equation method.\n",
    "    You should add a new row with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :return: prediction\n",
    "    :rtype: np.array\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# prediction = normal_equation_prediction(X, y) \n",
    "# plot_points_regression(X, y, title, xlabel, ylabel, prediction=prediction,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
